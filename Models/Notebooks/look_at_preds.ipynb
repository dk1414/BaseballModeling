{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Datasets.BaseballDataset import BaseballDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config_path = \"../data/config.json\"\n",
    "data_path = \"../data/mini_train.csv\"\n",
    "sequence_length = 200\n",
    "data = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = BaseballDataset(data,data_config_path,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(1)].transpose(0, 1)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_encoder_layers, hidden_dim, output_dim, sequence_length, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.positional_encoding = PositionalEncoding(hidden_dim, dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x[:, -1, :]  # Use the output of the last pitch in the sequence\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_model(model_path, config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    model = TransformerModel(\n",
    "        input_dim=config['input_dim'],\n",
    "        num_heads=config['num_heads'],\n",
    "        num_encoder_layers=config['num_encoder_layers'],\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        output_dim=config['output_dim'],\n",
    "        sequence_length=config['sequence_length'],\n",
    "        dropout=config.get('dropout', 0.1)  # Optional: provide a default value for dropout if not in config\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def make_preds(model, dataset, scaler_path, device, batch_size):\n",
    "\n",
    "    #get column names in correct order\n",
    "    flat_cat_names = []\n",
    "    for names in dataset.categorical_label_names:\n",
    "        flat_cat_names = flat_cat_names + names \n",
    "    col_names = dataset.continuous_label_names + flat_cat_names\n",
    "\n",
    "    #create dataloader for dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds_array = [] #keep trask of preds for each batch\n",
    "    true_array = [] #keep track of true values\n",
    "    with torch.no_grad():\n",
    "        idx = 0\n",
    "        for sequence_tensor, cont_target_tensor, cat_target_tensor in loader:\n",
    "            idx += 1\n",
    "            if idx % 10 == 0:\n",
    "                print(f\"Starting Batch: {idx}\")\n",
    "                \n",
    "            sequence_tensor, cont_target_tensor = sequence_tensor.to(device), cont_target_tensor.to(device)\n",
    "            cat_targets = [t.to(device) for t in cat_target_tensor]\n",
    "            output = model(sequence_tensor)\n",
    "\n",
    "            #first k logits correspond to continuous outputs, k = cont_target.size(1)\n",
    "            cont_output = output[:, :cont_target_tensor.size(1)].cpu().squeeze(0).detach().numpy()\n",
    "            cont_targets = cont_target_tensor.cpu().squeeze(0).detach().numpy()\n",
    "\n",
    "            #can have multiple kinds of categorical outputs. If cat_targets is (batch_size, 2, 10), there are 2 kinds of cateogorical outputs, each with 10 values.\n",
    "            #The first 10 logits after the continuous logits will correspond to first categorical output, second 10 to the second, so this requires multiple softmaxes\n",
    "            cat_probs = []\n",
    "            cat_target_probs = []\n",
    "            start_idx = cont_target_tensor.size(1)\n",
    "            for cat_target in cat_targets:\n",
    "                end_idx = start_idx + cat_target.size(1)\n",
    "                cat_probs.append(nn.functional.softmax(output[:, start_idx:end_idx],dim=1).cpu().squeeze(0).detach().numpy())\n",
    "                cat_target_probs.append(cat_target.cpu().squeeze(0).detach().numpy())\n",
    "                start_idx = end_idx\n",
    "    \n",
    "            #cat continuous and categorical outputs together\n",
    "            preds = cont_output\n",
    "            for probs in cat_probs:\n",
    "                preds = np.concatenate((preds, probs),axis=1)\n",
    "            \n",
    "            preds_array.append(preds)\n",
    "\n",
    "            true = cont_targets\n",
    "            for probs in cat_target_probs:\n",
    "                true = np.concatenate((true, probs),axis=1)\n",
    "            \n",
    "            true_array.append(true)\n",
    "\n",
    "    #make single preds pd     \n",
    "    preds_array = np.vstack(preds_array)\n",
    "    preds_pd = pd.DataFrame(preds_array, columns=col_names)\n",
    "\n",
    "    true_array = np.vstack(true_array)\n",
    "    true_pd = pd.DataFrame(true_array, columns=col_names)\n",
    "\n",
    "    #scale continuous outputs back to real values\n",
    "    with open(scaler_path, \"rb\") as file:\n",
    "        scalers = pickle.load(file)\n",
    "\n",
    "    for column, scaler in scalers.items():\n",
    "        if column in preds_pd:\n",
    "            preds_pd[column] = (preds_pd[column] * scaler.scale_) + scaler.mean_\n",
    "            true_pd[column] = (true_pd[column] * scaler.scale_) + scaler.mean_\n",
    "    \n",
    "\n",
    "    return preds_pd, true_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (embedding): Linear(in_features=75, out_features=72, bias=True)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=72, out_features=72, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=72, out_features=72, bias=True)\n",
       "        (norm1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_layers): Sequential(\n",
       "    (0): Linear(in_features=72, out_features=72, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=72, out_features=24, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_path = \"tiny_data_grid_experiment/h8_e8_h72_d0.1_lp0.5_lr0.001_ep50/transformer_model.pth\"\n",
    "c_path = \"tiny_data_grid_experiment/h8_e8_h72_d0.1_lp0.5_lr0.001_ep50/model_config.json\"\n",
    "model = load_model(m_path, c_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch: 10\n",
      "Starting Batch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\declan\\anaconda3\\envs\\pytorchCUDA\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.1 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "preds, true = make_preds(model,mini_dataset,\"../data/statcast_2023-2024_cleaned_scalers.pkl\",device, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>launch_speed</th>\n",
       "      <th>hc_x</th>\n",
       "      <th>hc_y</th>\n",
       "      <th>launch_angle</th>\n",
       "      <th>events_B</th>\n",
       "      <th>events_S</th>\n",
       "      <th>events_double</th>\n",
       "      <th>events_field_out</th>\n",
       "      <th>events_hit_by_pitch</th>\n",
       "      <th>events_home_run</th>\n",
       "      <th>...</th>\n",
       "      <th>hit_location_0.0</th>\n",
       "      <th>hit_location_1.0</th>\n",
       "      <th>hit_location_2.0</th>\n",
       "      <th>hit_location_3.0</th>\n",
       "      <th>hit_location_4.0</th>\n",
       "      <th>hit_location_5.0</th>\n",
       "      <th>hit_location_6.0</th>\n",
       "      <th>hit_location_7.0</th>\n",
       "      <th>hit_location_8.0</th>\n",
       "      <th>hit_location_9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.764048</td>\n",
       "      <td>53.867767</td>\n",
       "      <td>53.860563</td>\n",
       "      <td>53.784510</td>\n",
       "      <td>0.997373</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.046915e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>2.567186e-06</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.390405e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.247183e-06</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.746073</td>\n",
       "      <td>53.860694</td>\n",
       "      <td>53.869212</td>\n",
       "      <td>53.812892</td>\n",
       "      <td>0.995757</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.089696e-03</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>8.929605e-06</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>8.427814e-06</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>6.182944e-06</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.919176</td>\n",
       "      <td>55.056432</td>\n",
       "      <td>54.986871</td>\n",
       "      <td>54.766815</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.630928</td>\n",
       "      <td>9.602335e-05</td>\n",
       "      <td>0.087825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071173</td>\n",
       "      <td>2.277478e-02</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.077221</td>\n",
       "      <td>9.436519e-02</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.161335</td>\n",
       "      <td>1.561804e-01</td>\n",
       "      <td>0.164030</td>\n",
       "      <td>0.138685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.772328</td>\n",
       "      <td>53.844697</td>\n",
       "      <td>53.852248</td>\n",
       "      <td>53.811501</td>\n",
       "      <td>0.990320</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>5.559679e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>4.604223e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.275414e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.726683e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.779098</td>\n",
       "      <td>53.846921</td>\n",
       "      <td>53.850949</td>\n",
       "      <td>53.810150</td>\n",
       "      <td>0.994781</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.028626e-04</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>1.101750e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.199938e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>2.124563e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>54.026020</td>\n",
       "      <td>53.818864</td>\n",
       "      <td>53.823651</td>\n",
       "      <td>54.080974</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.998211</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>8.938545e-07</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998270</td>\n",
       "      <td>2.695666e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1.078622e-04</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>2.175103e-04</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>54.604809</td>\n",
       "      <td>54.753780</td>\n",
       "      <td>54.852090</td>\n",
       "      <td>54.510408</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.056537</td>\n",
       "      <td>0.594656</td>\n",
       "      <td>2.565821e-04</td>\n",
       "      <td>0.051700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049152</td>\n",
       "      <td>3.870830e-02</td>\n",
       "      <td>0.157678</td>\n",
       "      <td>0.053675</td>\n",
       "      <td>6.071455e-02</td>\n",
       "      <td>0.105687</td>\n",
       "      <td>0.144597</td>\n",
       "      <td>2.046981e-01</td>\n",
       "      <td>0.076841</td>\n",
       "      <td>0.108248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>54.120436</td>\n",
       "      <td>53.819953</td>\n",
       "      <td>53.826137</td>\n",
       "      <td>54.186605</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.999017</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>5.159933e-07</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998962</td>\n",
       "      <td>1.768196e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>6.533314e-05</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.300703e-04</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>54.096018</td>\n",
       "      <td>53.826697</td>\n",
       "      <td>53.814396</td>\n",
       "      <td>54.163913</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.997946</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>1.310113e-06</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996928</td>\n",
       "      <td>4.807348e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>1.882192e-04</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>4.292411e-04</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>54.893726</td>\n",
       "      <td>55.018021</td>\n",
       "      <td>55.056175</td>\n",
       "      <td>54.690130</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.049411</td>\n",
       "      <td>0.723895</td>\n",
       "      <td>5.668797e-05</td>\n",
       "      <td>0.054692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059044</td>\n",
       "      <td>2.587155e-02</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.061322</td>\n",
       "      <td>9.859014e-02</td>\n",
       "      <td>0.113079</td>\n",
       "      <td>0.192901</td>\n",
       "      <td>1.531455e-01</td>\n",
       "      <td>0.133937</td>\n",
       "      <td>0.157954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      launch_speed       hc_x       hc_y  launch_angle  events_B  events_S  \\\n",
       "0        53.764048  53.867767  53.860563     53.784510  0.997373  0.002431   \n",
       "1        53.746073  53.860694  53.869212     53.812892  0.995757  0.002842   \n",
       "2        54.919176  55.056432  54.986871     54.766815  0.000718  0.003420   \n",
       "3        53.772328  53.844697  53.852248     53.811501  0.990320  0.009557   \n",
       "4        53.779098  53.846921  53.850949     53.810150  0.994781  0.004904   \n",
       "...            ...        ...        ...           ...       ...       ...   \n",
       "2781     54.026020  53.818864  53.823651     54.080974  0.001054  0.998211   \n",
       "2782     54.604809  54.753780  54.852090     54.510408  0.000287  0.001259   \n",
       "2783     54.120436  53.819953  53.826137     54.186605  0.000641  0.999017   \n",
       "2784     54.096018  53.826697  53.814396     54.163913  0.000812  0.997946   \n",
       "2785     54.893726  55.018021  55.056175     54.690130  0.000344  0.001522   \n",
       "\n",
       "      events_double  events_field_out  events_hit_by_pitch  events_home_run  \\\n",
       "0          0.000002          0.000019         1.046915e-04         0.000004   \n",
       "1          0.000007          0.000046         1.089696e-03         0.000011   \n",
       "2          0.073950          0.630928         9.602335e-05         0.087825   \n",
       "3          0.000001          0.000012         5.559679e-05         0.000002   \n",
       "4          0.000002          0.000015         2.028626e-04         0.000003   \n",
       "...             ...               ...                  ...              ...   \n",
       "2781       0.000024          0.000494         8.938545e-07         0.000068   \n",
       "2782       0.056537          0.594656         2.565821e-04         0.051700   \n",
       "2783       0.000014          0.000218         5.159933e-07         0.000034   \n",
       "2784       0.000041          0.000850         1.310113e-06         0.000110   \n",
       "2785       0.049411          0.723895         5.668797e-05         0.054692   \n",
       "\n",
       "      ...  hit_location_0.0  hit_location_1.0  hit_location_2.0  \\\n",
       "0     ...          0.999923      2.567186e-06          0.000012   \n",
       "1     ...          0.999832      8.929605e-06          0.000021   \n",
       "2     ...          0.071173      2.277478e-02          0.007634   \n",
       "3     ...          0.999977      4.604223e-07          0.000007   \n",
       "4     ...          0.999937      1.101750e-06          0.000026   \n",
       "...   ...               ...               ...               ...   \n",
       "2781  ...          0.998270      2.695666e-05          0.000004   \n",
       "2782  ...          0.049152      3.870830e-02          0.157678   \n",
       "2783  ...          0.998962      1.768196e-05          0.000004   \n",
       "2784  ...          0.996928      4.807348e-05          0.000007   \n",
       "2785  ...          0.059044      2.587155e-02          0.004157   \n",
       "\n",
       "      hit_location_3.0  hit_location_4.0  hit_location_5.0  hit_location_6.0  \\\n",
       "0             0.000008      3.390405e-06          0.000007          0.000008   \n",
       "1             0.000017      8.427814e-06          0.000014          0.000018   \n",
       "2             0.077221      9.436519e-02          0.106601          0.161335   \n",
       "3             0.000002      8.275414e-07          0.000002          0.000002   \n",
       "4             0.000005      2.199938e-06          0.000004          0.000005   \n",
       "...                ...               ...               ...               ...   \n",
       "2781          0.000126      1.078622e-04          0.000124          0.000126   \n",
       "2782          0.053675      6.071455e-02          0.105687          0.144597   \n",
       "2783          0.000076      6.533314e-05          0.000072          0.000064   \n",
       "2784          0.000216      1.882192e-04          0.000196          0.000227   \n",
       "2785          0.061322      9.859014e-02          0.113079          0.192901   \n",
       "\n",
       "      hit_location_7.0  hit_location_8.0  hit_location_9.0  \n",
       "0         3.247183e-06          0.000018          0.000014  \n",
       "1         6.182944e-06          0.000043          0.000031  \n",
       "2         1.561804e-01          0.164030          0.138685  \n",
       "3         9.726683e-07          0.000004          0.000003  \n",
       "4         2.124563e-06          0.000009          0.000008  \n",
       "...                ...               ...               ...  \n",
       "2781      2.175103e-04          0.000738          0.000259  \n",
       "2782      2.046981e-01          0.076841          0.108248  \n",
       "2783      1.300703e-04          0.000481          0.000128  \n",
       "2784      4.292411e-04          0.001301          0.000460  \n",
       "2785      1.531455e-01          0.133937          0.157954  \n",
       "\n",
       "[2786 rows x 24 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2786.000000\n",
       "mean       54.009474\n",
       "std         0.397340\n",
       "min        53.741617\n",
       "25%        53.821997\n",
       "50%        53.850706\n",
       "75%        53.879205\n",
       "max        55.171426\n",
       "Name: hc_x, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds['hc_x'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2786.000000\n",
       "mean       54.100048\n",
       "std         0.501494\n",
       "min        53.776220\n",
       "25%        53.776220\n",
       "50%        53.776220\n",
       "75%        54.539128\n",
       "max        55.417279\n",
       "Name: launch_angle, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true['launch_angle'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
