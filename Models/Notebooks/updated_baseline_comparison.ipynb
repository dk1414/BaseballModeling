{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "\n",
    "from Datasets.BaseballDataset import BaseballDataset\n",
    "from BaselineModel.BaselineModel import BaselineModel\n",
    "from TransformerModel.TransformerModelRedisual import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config_path = \"../../data/configv3.json\"\n",
    "full_data_path = \"../../data/full_cleaned_94.csv\"\n",
    "full_data = pd.read_csv(full_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_path = \"../../data/full_scalers_94.pkl\"\n",
    "with open(scaler_path, \"rb\") as file:\n",
    "    scalers = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "m_path = \"../fixed_large_400/h12_e12_h96_d0_lp0.3_lr1e-05_ep40/transformer_model.pth\"\n",
    "c_path = \"../fixed_large_400/h12_e12_h96_d0_lp0.3_lr1e-05_ep40//model_config.json\"\n",
    "\n",
    "transformer_model = TransformerHelper(m_path,c_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer model trained on 2017 data, so baseline model will use that as well\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = pd.to_datetime(\"2017-01-01\")\n",
    "end_date = pd.to_datetime(\"2018-01-01\")\n",
    "full_data['game_date'] = pd.to_datetime(full_data['game_date'])\n",
    "total_days = (end_date - start_date).days\n",
    "split_date = pd.to_datetime(start_date) + timedelta(days=int(total_days * 0.6))\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train = full_data[(full_data['game_date'] > start_date) & (full_data['game_date'] < split_date)].reset_index(drop=True)\n",
    "valid = full_data[(full_data['game_date'] > \"2024-01-01\")].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BaseballDataset(train,data_config_path,sequence_length)\n",
    "test_dataset = BaseballDataset(valid,data_config_path,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating matrices\n",
      "Processing batch 0\n",
      "Concatenating and appending data\n",
      "Processing batch 10\n",
      "Concatenating and appending data\n",
      "Processing batch 20\n",
      "Concatenating and appending data\n",
      "Processing batch 30\n",
      "Concatenating and appending data\n",
      "Processing batch 40\n",
      "Concatenating and appending data\n",
      "Processing batch 50\n",
      "Concatenating and appending data\n",
      "Processing batch 60\n",
      "Concatenating and appending data\n",
      "Processing batch 70\n",
      "Concatenating and appending data\n",
      "Processing batch 80\n",
      "Concatenating and appending data\n",
      "Processing batch 90\n",
      "Concatenating and appending data\n",
      "Processing batch 100\n",
      "Concatenating and appending data\n",
      "Processing batch 110\n",
      "Concatenating and appending data\n",
      "Processing batch 120\n",
      "Concatenating and appending data\n",
      "Processing batch 130\n",
      "Concatenating and appending data\n",
      "Processing batch 140\n",
      "Final concatenation\n",
      "Finished processing all batches\n",
      "Starting cont train\n",
      "Starting cat train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\declan\\anaconda3\\envs\\pytorchCUDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\declan\\anaconda3\\envs\\pytorchCUDA\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#train baseline model, uses logistic regression for categorical preds and linear regression for continuous preds\n",
    "baseline_model = BaselineModel(train_dataset, scaler_path, max_iters=100, pred_mode=False, pred_mean=False)\n",
    "baseline_model.train(batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make preds with transformer model\n",
    "trans_preds, true = transformer_model.make_preds(test_dataset, scaler_path, device, 2000, scale=True)\n",
    "\n",
    "\n",
    "#make preds with baseline model\n",
    "loader = DataLoader(test_dataset, batch_size=2000, shuffle=False, num_workers=0)\n",
    "base_preds = []\n",
    "for seq, _, _ in loader:\n",
    "\n",
    "    base_preds.append(baseline_model.predict(seq, scale=True))\n",
    "\n",
    "baseline_preds = pd.concat(base_preds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch: 10\n",
      "Starting Batch: 20\n",
      "Starting Batch: 30\n",
      "Starting Batch: 40\n",
      "Starting Batch: 50\n",
      "Starting Batch: 60\n",
      "Starting Batch: 70\n",
      "Starting Batch: 80\n",
      "Starting Batch: 90\n",
      "Starting Batch: 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#both models with share the same true values\n",
    "\n",
    "\n",
    "# First 4 columns are continuous preds/labels\n",
    "trans_cont_preds = trans_preds.iloc[:, 0:4]\n",
    "base_cont_preds = baseline_preds.iloc[:,0:4]\n",
    "cont_true = true.iloc[:, 0:4]\n",
    "\n",
    "# Next 10 columns are probabilities for the events categorical feature\n",
    "trans_events_preds = trans_preds.iloc[:, 4:14]\n",
    "base_events_preds = baseline_preds.iloc[:, 4:14]\n",
    "events_true = true.iloc[:, 4:14]\n",
    "\n",
    "\n",
    "# Last 10 columns are probabilities for the hit_location categorical feature\n",
    "trans_loc_preds = trans_preds.iloc[:, 14:]\n",
    "base_loc_preds = baseline_preds.iloc[:,14:]\n",
    "loc_true = true.iloc[:, 14:]\n",
    "\n",
    "\n",
    "trans_cont_error = np.mean(np.abs(cont_true - trans_cont_preds), axis=1)\n",
    "base_cont_error = np.mean(np.abs(cont_true - base_cont_preds), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#calculate top k precision\n",
    "top_k = 4\n",
    "\n",
    "# Get top-k predictions for each sample, returning the numeric index instead of column names\n",
    "trans_events_top_k_preds = trans_events_preds.apply(lambda x: x.nlargest(top_k).index.map(lambda name: trans_events_preds.columns.get_loc(name)), axis=1)\n",
    "trans_loc_top_k_preds = trans_loc_preds.apply(lambda x: x.nlargest(top_k).index.map(lambda name: trans_loc_preds.columns.get_loc(name)), axis=1)\n",
    "\n",
    "base_events_top_k_preds = base_events_preds.apply(lambda x: x.nlargest(top_k).index.map(lambda name: base_events_preds.columns.get_loc(name)), axis=1)\n",
    "base_loc_top_k_preds = base_loc_preds.apply(lambda x: x.nlargest(top_k).index.map(lambda name: base_loc_preds.columns.get_loc(name)), axis=1)\n",
    "\n",
    "# Now the predictions are stored as the numeric indices corresponding to the classes\n",
    "\n",
    "# Compute precision for each class\n",
    "trans_events_class_precisions = []\n",
    "trans_loc_class_precisions = []\n",
    "\n",
    "base_events_class_precisions = []\n",
    "base_loc_class_precisions = []\n",
    "\n",
    "# For each class in events and hit_location, calculate top-k precision\n",
    "for class_idx in range(10):\n",
    "    # For events precision\n",
    "    true_class_mask = events_true.iloc[:, class_idx] == 1  # Find where this class is the true class\n",
    "    true_class_indices = events_true.index[true_class_mask]\n",
    "    \n",
    "    # Check if this class is in the top-k predictions when it's the true class\n",
    "    trans_event_precision = np.mean([1 if class_idx in trans_events_top_k_preds.iloc[i] else 0 for i in true_class_indices])\n",
    "    trans_events_class_precisions.append(trans_event_precision)\n",
    "\n",
    "    base_event_precision = np.mean([1 if class_idx in base_events_top_k_preds.iloc[i] else 0 for i in true_class_indices])\n",
    "    base_events_class_precisions.append(base_event_precision)\n",
    "\n",
    "    # For hit location precision\n",
    "    true_class_mask = loc_true.iloc[:, class_idx] == 1  # Find where this class is the true class\n",
    "    true_class_indices = loc_true.index[true_class_mask]\n",
    "\n",
    "    # Check if this class is in the top-k predictions when it's the true class\n",
    "    trans_loc_precision = np.mean([1 if class_idx in trans_loc_top_k_preds.iloc[i] else 0 for i in true_class_indices])\n",
    "    trans_loc_class_precisions.append(trans_loc_precision)\n",
    "\n",
    "    base_loc_precision = np.mean([1 if class_idx in base_loc_top_k_preds.iloc[i] else 0 for i in true_class_indices])\n",
    "    base_loc_class_precisions.append(base_loc_precision)\n",
    "\n",
    "\n",
    "# Retrieve the class names for 'events' and 'hit_location'\n",
    "event_class_names = test_dataset.categorical_label_names[0]\n",
    "loc_class_names = test_dataset.categorical_label_names[1]\n",
    "\n",
    "# Identify the column indices for classes to ignore\n",
    "ignored_event_classes = ['events_S', 'events_B']\n",
    "ignored_loc_classes = ['hit_location_0.0']\n",
    "\n",
    "# Get the indices of the ignored classes\n",
    "ignored_event_indices = [event_class_names.index(cls) for cls in ignored_event_classes]\n",
    "ignored_loc_indices = [loc_class_names.index(cls) for cls in ignored_loc_classes]\n",
    "\n",
    "# Determine the true class indices for 'events' and 'hit_location'\n",
    "true_event_classes = events_true.idxmax(axis=1).map(\n",
    "    lambda name: events_true.columns.get_loc(name)\n",
    ").values\n",
    "true_loc_classes = loc_true.idxmax(axis=1).map(\n",
    "    lambda name: loc_true.columns.get_loc(name)\n",
    ").values\n",
    "\n",
    "# Create masks to exclude ignored classes\n",
    "# For 'events': Exclude samples where true class is in ignored_event_indices\n",
    "events_mask = ~np.isin(true_event_classes, ignored_event_indices)\n",
    "\n",
    "# For 'hit_location': Exclude samples where true class is in ignored_loc_indices\n",
    "loc_mask = ~np.isin(true_loc_classes, ignored_loc_indices)\n",
    "\n",
    "# Apply the masks to filter out ignored examples\n",
    "# Filtered indices for 'events'\n",
    "filtered_event_indices = np.where(events_mask)[0]\n",
    "\n",
    "# Filtered indices for 'hit_location'\n",
    "filtered_loc_indices = np.where(loc_mask)[0]\n",
    "\n",
    "# Convert top-k predictions to lists for easier processing\n",
    "trans_events_top_k_list = trans_events_top_k_preds.tolist()\n",
    "base_events_top_k_list = base_events_top_k_preds.tolist()\n",
    "\n",
    "trans_loc_top_k_list = trans_loc_top_k_preds.tolist()\n",
    "base_loc_top_k_list = base_loc_top_k_preds.tolist()\n",
    "\n",
    "# Calculate Top-K Accuracy for 'events' excluding ignored classes\n",
    "trans_events_top_k_correct = [\n",
    "    true_event_classes[i] in trans_events_top_k_list[i]\n",
    "    for i in filtered_event_indices\n",
    "]\n",
    "base_events_top_k_correct = [\n",
    "    true_event_classes[i] in base_events_top_k_list[i]\n",
    "    for i in filtered_event_indices\n",
    "]\n",
    "\n",
    "# Calculate Top-K Accuracy for 'hit_location' excluding ignored classes\n",
    "trans_loc_top_k_correct = [\n",
    "    true_loc_classes[i] in trans_loc_top_k_list[i]\n",
    "    for i in filtered_loc_indices\n",
    "]\n",
    "base_loc_top_k_correct = [\n",
    "    true_loc_classes[i] in base_loc_top_k_list[i]\n",
    "    for i in filtered_loc_indices\n",
    "]\n",
    "\n",
    "# Calculate the mean accuracy\n",
    "trans_events_top_k_accuracy = np.mean(trans_events_top_k_correct) if len(trans_events_top_k_correct) > 0 else np.nan\n",
    "base_events_top_k_accuracy = np.mean(base_events_top_k_correct) if len(base_events_top_k_correct) > 0 else np.nan\n",
    "\n",
    "trans_loc_top_k_accuracy = np.mean(trans_loc_top_k_correct) if len(trans_loc_top_k_correct) > 0 else np.nan\n",
    "base_loc_top_k_accuracy = np.mean(base_loc_top_k_correct) if len(base_loc_top_k_correct) > 0 else np.nan\n",
    "\n",
    "# (Optional) Calculate Combined Top-K Accuracy Across All Categorical Features\n",
    "# Ensure that both 'events' and 'hit_location' are not in ignored classes for combined accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch: 10\n",
      "Starting Batch: 20\n",
      "Starting Batch: 30\n",
      "Starting Batch: 40\n",
      "Starting Batch: 50\n",
      "Starting Batch: 60\n",
      "Starting Batch: 70\n",
      "Starting Batch: 80\n",
      "Starting Batch: 90\n",
      "Starting Batch: 100\n",
      "Starting Batch: 10\n",
      "Starting Batch: 20\n",
      "Starting Batch: 30\n",
      "Starting Batch: 40\n",
      "Starting Batch: 50\n",
      "Starting Batch: 60\n",
      "Starting Batch: 70\n",
      "Starting Batch: 80\n",
      "Starting Batch: 90\n",
      "Starting Batch: 100\n",
      "Starting Batch: 110\n",
      "Starting Batch: 120\n",
      "Starting Batch: 130\n",
      "Starting Batch: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\declan\\AppData\\Local\\Temp\\ipykernel_10160\\2587051609.py:76: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.25' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baseline_events_probs.iloc[i, sampled] = 1.0 / 4  # Equal probability\n",
      "C:\\Users\\declan\\AppData\\Local\\Temp\\ipykernel_10160\\2587051609.py:79: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.25' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  baseline_loc_probs.iloc[i, sampled] = 1.0 / 4  # Equal probability\n"
     ]
    }
   ],
   "source": [
    "# 1. Make Predictions with Transformer Model\n",
    "# ===========================================\n",
    "trans_preds, true = transformer_model.make_preds(\n",
    "    test_dataset, scaler_path, device, 2000, scale=True\n",
    ")\n",
    "\n",
    "# 2. Generate Baseline Predictions Based on Class Distributions\n",
    "# ===============================================================\n",
    "\n",
    "# Compute class distributions from the training dataset\n",
    "train_preds, train_true = transformer_model.make_preds(\n",
    "    train_dataset, scaler_path, device, 2000, scale=True\n",
    ")\n",
    "\n",
    "# Split true labels into categorical features\n",
    "train_events_true = train_true.iloc[:, 4:14]\n",
    "train_loc_true = train_true.iloc[:, 14:]\n",
    "\n",
    "# Compute class counts\n",
    "events_class_counts = train_events_true.sum(axis=0)\n",
    "loc_class_counts = train_loc_true.sum(axis=0)\n",
    "\n",
    "# Compute class distributions (probabilities)\n",
    "events_class_distribution = events_class_counts / events_class_counts.sum()\n",
    "loc_class_distribution = loc_class_counts / loc_class_counts.sum()\n",
    "\n",
    "# Convert distributions to numpy arrays for sampling\n",
    "events_class_probs = events_class_distribution.values\n",
    "loc_class_probs = loc_class_distribution.values\n",
    "\n",
    "# Retrieve class names\n",
    "event_class_names = test_dataset.categorical_label_names[0]\n",
    "loc_class_names = test_dataset.categorical_label_names[1]\n",
    "\n",
    "def sample_top_k_classes(class_names, class_probs, top_k=4, num_samples=2000):\n",
    "    \"\"\"\n",
    "    Samples top-k classes without replacement based on the provided class probabilities.\n",
    "\n",
    "    Args:\n",
    "        class_names (list): List of class names.\n",
    "        class_probs (numpy.ndarray): Array of class probabilities.\n",
    "        top_k (int): Number of classes to sample.\n",
    "        num_samples (int): Number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        list of lists: Each sublist contains the indices of the sampled classes for a sample.\n",
    "    \"\"\"\n",
    "    sampled_classes = np.array([\n",
    "        np.random.choice(len(class_names), size=top_k, replace=False, p=class_probs)\n",
    "        for _ in range(num_samples)\n",
    "    ])\n",
    "    return sampled_classes.tolist()\n",
    "\n",
    "# Determine the number of test samples\n",
    "num_test_samples = len(test_dataset)\n",
    "\n",
    "# Sample top-k classes for 'events' and 'hit_location'\n",
    "baseline_events_top_k = sample_top_k_classes(\n",
    "    event_class_names, events_class_probs, top_k=4, num_samples=num_test_samples\n",
    ")\n",
    "baseline_loc_top_k = sample_top_k_classes(\n",
    "    loc_class_names, loc_class_probs, top_k=4, num_samples=num_test_samples\n",
    ")\n",
    "\n",
    "# Convert sampled classes to probabilities\n",
    "# Initialize probability DataFrames with zeros\n",
    "baseline_events_probs = pd.DataFrame(\n",
    "    0, index=np.arange(num_test_samples), columns=event_class_names\n",
    ")\n",
    "baseline_loc_probs = pd.DataFrame(\n",
    "    0, index=np.arange(num_test_samples), columns=loc_class_names\n",
    ")\n",
    "\n",
    "# Assign equal probability to sampled classes\n",
    "for i, sampled in enumerate(baseline_events_top_k):\n",
    "    baseline_events_probs.iloc[i, sampled] = 1.0 / 4  # Equal probability\n",
    "\n",
    "for i, sampled in enumerate(baseline_loc_top_k):\n",
    "    baseline_loc_probs.iloc[i, sampled] = 1.0 / 4  # Equal probability\n",
    "\n",
    "# Handle continuous predictions for baseline\n",
    "# Option 1: Set to mean of training continuous labels\n",
    "# Compute mean from training data\n",
    "trans_cont_mean = train_true.iloc[:, 0:4].mean().values  # Replace with actual mean if different\n",
    "baseline_cont_preds = pd.DataFrame(\n",
    "    np.tile(trans_cont_mean, (num_test_samples, 1)),\n",
    "    columns=true.iloc[:, 0:4].columns\n",
    ")\n",
    "\n",
    "# Combine continuous and categorical predictions\n",
    "baseline_preds = pd.concat([\n",
    "    baseline_cont_preds.reset_index(drop=True),\n",
    "    baseline_events_probs.reset_index(drop=True),\n",
    "    baseline_loc_probs.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# 3. Process Transformer and Baseline Predictions\n",
    "# ================================================\n",
    "\n",
    "# Split predictions and true values into continuous and categorical parts\n",
    "# First 4 columns are continuous preds/labels\n",
    "trans_cont_preds = trans_preds.iloc[:, 0:4]\n",
    "base_cont_preds = baseline_preds.iloc[:, 0:4]\n",
    "cont_true = true.iloc[:, 0:4]\n",
    "\n",
    "# Next 10 columns are probabilities for the 'events' categorical feature\n",
    "trans_events_preds = trans_preds.iloc[:, 4:14]\n",
    "base_events_preds = baseline_preds.iloc[:, 4:14]\n",
    "events_true = true.iloc[:, 4:14]\n",
    "\n",
    "# Last 10 columns are probabilities for the 'hit_location' categorical feature\n",
    "trans_loc_preds = trans_preds.iloc[:, 14:]\n",
    "base_loc_preds = baseline_preds.iloc[:, 14:]\n",
    "loc_true = true.iloc[:, 14:]\n",
    "\n",
    "# Calculate mean absolute error for continuous predictions\n",
    "trans_cont_error = np.mean(np.abs(cont_true - trans_cont_preds), axis=1)\n",
    "base_cont_error = np.mean(np.abs(cont_true - base_cont_preds), axis=1)\n",
    "\n",
    "# 4. Calculate Top-K Precision for Categorical Features\n",
    "# =======================================================\n",
    "\n",
    "top_k = 4\n",
    "\n",
    "# Get top-k predictions for each sample, returning the numeric index instead of column names\n",
    "trans_events_top_k_preds = trans_events_preds.apply(\n",
    "    lambda x: x.nlargest(top_k).index.map(lambda name: trans_events_preds.columns.get_loc(name)),\n",
    "    axis=1\n",
    ")\n",
    "trans_loc_top_k_preds = trans_loc_preds.apply(\n",
    "    lambda x: x.nlargest(top_k).index.map(lambda name: trans_loc_preds.columns.get_loc(name)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "base_events_top_k_preds = base_events_preds.apply(\n",
    "    lambda x: x.nlargest(top_k).index.map(lambda name: base_events_preds.columns.get_loc(name)),\n",
    "    axis=1\n",
    ")\n",
    "base_loc_top_k_preds = base_loc_preds.apply(\n",
    "    lambda x: x.nlargest(top_k).index.map(lambda name: base_loc_preds.columns.get_loc(name)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Compute precision for each class\n",
    "trans_events_class_precisions = []\n",
    "trans_loc_class_precisions = []\n",
    "\n",
    "base_events_class_precisions = []\n",
    "base_loc_class_precisions = []\n",
    "\n",
    "# For each class in 'events' and 'hit_location', calculate top-k precision\n",
    "for class_idx in range(10):\n",
    "    # For 'events' precision\n",
    "    true_class_mask = events_true.iloc[:, class_idx] == 1  # Find where this class is the true class\n",
    "    true_class_indices = events_true.index[true_class_mask]\n",
    "\n",
    "    # Check if this class is in the top-k predictions when it's the true class\n",
    "    trans_event_precision = np.mean([\n",
    "        1 if class_idx in trans_events_top_k_preds.iloc[i] else 0 \n",
    "        for i in true_class_indices\n",
    "    ])\n",
    "    trans_events_class_precisions.append(trans_event_precision)\n",
    "\n",
    "    base_event_precision = np.mean([\n",
    "        1 if class_idx in base_events_top_k_preds.iloc[i] else 0 \n",
    "        for i in true_class_indices\n",
    "    ])\n",
    "    base_events_class_precisions.append(base_event_precision)\n",
    "\n",
    "    # For 'hit_location' precision\n",
    "    true_class_mask = loc_true.iloc[:, class_idx] == 1  # Find where this class is the true class\n",
    "    true_class_indices = loc_true.index[true_class_mask]\n",
    "\n",
    "    # Check if this class is in the top-k predictions when it's the true class\n",
    "    trans_loc_precision = np.mean([\n",
    "        1 if class_idx in trans_loc_top_k_preds.iloc[i] else 0 \n",
    "        for i in true_class_indices\n",
    "    ])\n",
    "    trans_loc_class_precisions.append(trans_loc_precision)\n",
    "\n",
    "    base_loc_precision = np.mean([\n",
    "        1 if class_idx in base_loc_top_k_preds.iloc[i] else 0 \n",
    "        for i in true_class_indices\n",
    "    ])\n",
    "    base_loc_class_precisions.append(base_loc_precision)\n",
    "\n",
    "# 5. Exclude Certain Majority Classes from Evaluation\n",
    "# ======================================================\n",
    "\n",
    "# Identify the column indices for classes to ignore\n",
    "ignored_event_classes = ['events_S', 'events_B']\n",
    "ignored_loc_classes = ['hit_location_0.0']\n",
    "\n",
    "# Get the indices of the ignored classes\n",
    "ignored_event_indices = [event_class_names.index(cls) for cls in ignored_event_classes]\n",
    "ignored_loc_indices = [loc_class_names.index(cls) for cls in ignored_loc_classes]\n",
    "\n",
    "# Determine the true class indices for 'events' and 'hit_location'\n",
    "true_event_classes = events_true.idxmax(axis=1).map(\n",
    "    lambda name: events_true.columns.get_loc(name)\n",
    ").values\n",
    "true_loc_classes = loc_true.idxmax(axis=1).map(\n",
    "    lambda name: loc_true.columns.get_loc(name)\n",
    ").values\n",
    "\n",
    "# Create masks to exclude ignored classes\n",
    "# For 'events': Exclude samples where true class is in ignored_event_indices\n",
    "events_mask = ~np.isin(true_event_classes, ignored_event_indices)\n",
    "\n",
    "# For 'hit_location': Exclude samples where true class is in ignored_loc_indices\n",
    "loc_mask = ~np.isin(true_loc_classes, ignored_loc_indices)\n",
    "\n",
    "# Apply the masks to filter out ignored examples\n",
    "# Filtered indices for 'events'\n",
    "filtered_event_indices = np.where(events_mask)[0]\n",
    "\n",
    "# Filtered indices for 'hit_location'\n",
    "filtered_loc_indices = np.where(loc_mask)[0]\n",
    "\n",
    "# Convert top-k predictions to lists for easier processing\n",
    "trans_events_top_k_list = trans_events_top_k_preds.tolist()\n",
    "base_events_top_k_list = base_events_top_k_preds.tolist()\n",
    "\n",
    "trans_loc_top_k_list = trans_loc_top_k_preds.tolist()\n",
    "base_loc_top_k_list = base_loc_top_k_preds.tolist()\n",
    "\n",
    "# Calculate Top-K Accuracy for 'events' excluding ignored classes\n",
    "trans_events_top_k_correct = [\n",
    "    true_event_classes[i] in trans_events_top_k_list[i]\n",
    "    for i in filtered_event_indices\n",
    "]\n",
    "base_events_top_k_correct = [\n",
    "    true_event_classes[i] in base_events_top_k_list[i]\n",
    "    for i in filtered_event_indices\n",
    "]\n",
    "\n",
    "# Calculate Top-K Accuracy for 'hit_location' excluding ignored classes\n",
    "trans_loc_top_k_correct = [\n",
    "    true_loc_classes[i] in trans_loc_top_k_list[i]\n",
    "    for i in filtered_loc_indices\n",
    "]\n",
    "base_loc_top_k_correct = [\n",
    "    true_loc_classes[i] in base_loc_top_k_list[i]\n",
    "    for i in filtered_loc_indices\n",
    "]\n",
    "\n",
    "# Calculate the mean accuracy\n",
    "trans_events_top_k_accuracy = np.mean(trans_events_top_k_correct) if len(trans_events_top_k_correct) > 0 else np.nan\n",
    "base_events_top_k_accuracy = np.mean(base_events_top_k_correct) if len(base_events_top_k_correct) > 0 else np.nan\n",
    "\n",
    "trans_loc_top_k_accuracy = np.mean(trans_loc_top_k_correct) if len(trans_loc_top_k_correct) > 0 else np.nan\n",
    "base_loc_top_k_accuracy = np.mean(base_loc_top_k_correct) if len(base_loc_top_k_correct) > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top-4 Accuracy (Excluding Majority Classes) ===\n",
      "\n",
      "--- 'Events' Category ---\n",
      "Transformer Model - Top-4 Accuracy: 0.9433\n",
      "Baseline Model    - Top-4 Accuracy: 0.5378\n",
      "\n",
      "--- 'Hit Location' Category ---\n",
      "Transformer Model - Top-4 Accuracy: 0.6383\n",
      "Baseline Model    - Top-4 Accuracy: 0.4083\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"=== Top-{top_k} Accuracy (Excluding Majority Classes) ===\\n\")\n",
    "\n",
    "print(f\"--- 'Events' Category ---\")\n",
    "print(f\"Transformer Model - Top-{top_k} Accuracy: {trans_events_top_k_accuracy:.4f}\")\n",
    "print(f\"Baseline Model    - Top-{top_k} Accuracy: {base_events_top_k_accuracy:.4f}\\n\")\n",
    "\n",
    "print(f\"--- 'Hit Location' Category ---\")\n",
    "print(f\"Transformer Model - Top-{top_k} Accuracy: {trans_loc_top_k_accuracy:.4f}\")\n",
    "print(f\"Baseline Model    - Top-{top_k} Accuracy: {base_loc_top_k_accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['launch_speed', 'hc_x', 'hc_y', 'launch_angle']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.continuous_label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Event Precision (Top K 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>events_B</td>\n",
       "      <td>0.997692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>events_S</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events_double</td>\n",
       "      <td>0.432077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>events_field_out</td>\n",
       "      <td>0.999794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>events_hit_by_pitch</td>\n",
       "      <td>0.956971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>events_home_run</td>\n",
       "      <td>0.325567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>events_single</td>\n",
       "      <td>0.969103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>events_strikeout</td>\n",
       "      <td>0.993971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>events_triple</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>events_walk</td>\n",
       "      <td>0.996309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Class  Event Precision (Top K 4)\n",
       "0             events_B                   0.997692\n",
       "1             events_S                   1.000000\n",
       "2        events_double                   0.432077\n",
       "3     events_field_out                   0.999794\n",
       "4  events_hit_by_pitch                   0.956971\n",
       "5      events_home_run                   0.325567\n",
       "6        events_single                   0.969103\n",
       "7     events_strikeout                   0.993971\n",
       "8        events_triple                   0.000000\n",
       "9          events_walk                   0.996309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Event Precision (Top K 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>events_B</td>\n",
       "      <td>0.965045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>events_S</td>\n",
       "      <td>0.975201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events_double</td>\n",
       "      <td>0.130149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>events_field_out</td>\n",
       "      <td>0.759526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>events_hit_by_pitch</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>events_home_run</td>\n",
       "      <td>0.093829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>events_single</td>\n",
       "      <td>0.351028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>events_strikeout</td>\n",
       "      <td>0.483330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>events_triple</td>\n",
       "      <td>0.009091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>events_walk</td>\n",
       "      <td>0.205955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Class  Event Precision (Top K 4)\n",
       "0             events_B                   0.965045\n",
       "1             events_S                   0.975201\n",
       "2        events_double                   0.130149\n",
       "3     events_field_out                   0.759526\n",
       "4  events_hit_by_pitch                   0.015491\n",
       "5      events_home_run                   0.093829\n",
       "6        events_single                   0.351028\n",
       "7     events_strikeout                   0.483330\n",
       "8        events_triple                   0.009091\n",
       "9          events_walk                   0.205955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_class_names = test_dataset.categorical_label_names[0]\n",
    "loc_class_names = test_dataset.categorical_label_names[1]\n",
    "\n",
    "\n",
    "# Create DataFrames for the results\n",
    "trans_event_summary_df = pd.DataFrame({\n",
    "    'Class': event_class_names,\n",
    "    f'Event Precision (Top K {top_k})': trans_events_class_precisions\n",
    "\n",
    "})\n",
    "\n",
    "# Create DataFrames for the results\n",
    "base_event_summary_df = pd.DataFrame({\n",
    "    'Class': event_class_names,\n",
    "    f'Event Precision (Top K {top_k})': base_events_class_precisions\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "display(trans_event_summary_df)\n",
    "display(base_event_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Hit Loc Precision (Top K 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit_location_0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit_location_1.0</td>\n",
       "      <td>0.136722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit_location_2.0</td>\n",
       "      <td>0.156171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit_location_3.0</td>\n",
       "      <td>0.324655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit_location_4.0</td>\n",
       "      <td>0.533186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hit_location_5.0</td>\n",
       "      <td>0.520624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hit_location_6.0</td>\n",
       "      <td>0.599096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hit_location_7.0</td>\n",
       "      <td>0.785664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit_location_8.0</td>\n",
       "      <td>0.836177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hit_location_9.0</td>\n",
       "      <td>0.728159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Class  Hit Loc Precision (Top K 4)\n",
       "0  hit_location_0.0                     1.000000\n",
       "1  hit_location_1.0                     0.136722\n",
       "2  hit_location_2.0                     0.156171\n",
       "3  hit_location_3.0                     0.324655\n",
       "4  hit_location_4.0                     0.533186\n",
       "5  hit_location_5.0                     0.520624\n",
       "6  hit_location_6.0                     0.599096\n",
       "7  hit_location_7.0                     0.785664\n",
       "8  hit_location_8.0                     0.836177\n",
       "9  hit_location_9.0                     0.728159"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Hit Loc Precision (Top K 4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit_location_0.0</td>\n",
       "      <td>0.999581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit_location_1.0</td>\n",
       "      <td>0.129711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit_location_2.0</td>\n",
       "      <td>0.035264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit_location_3.0</td>\n",
       "      <td>0.242209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit_location_4.0</td>\n",
       "      <td>0.378888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hit_location_5.0</td>\n",
       "      <td>0.318086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hit_location_6.0</td>\n",
       "      <td>0.407006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hit_location_7.0</td>\n",
       "      <td>0.465129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit_location_8.0</td>\n",
       "      <td>0.510585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hit_location_9.0</td>\n",
       "      <td>0.475287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Class  Hit Loc Precision (Top K 4)\n",
       "0  hit_location_0.0                     0.999581\n",
       "1  hit_location_1.0                     0.129711\n",
       "2  hit_location_2.0                     0.035264\n",
       "3  hit_location_3.0                     0.242209\n",
       "4  hit_location_4.0                     0.378888\n",
       "5  hit_location_5.0                     0.318086\n",
       "6  hit_location_6.0                     0.407006\n",
       "7  hit_location_7.0                     0.465129\n",
       "8  hit_location_8.0                     0.510585\n",
       "9  hit_location_9.0                     0.475287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trans_loc_summary_df = pd.DataFrame({\n",
    "    'Class': loc_class_names,\n",
    "    f'Hit Loc Precision (Top K {top_k})': trans_loc_class_precisions\n",
    "\n",
    "})\n",
    "\n",
    "# Create DataFrames for the results\n",
    "base_loc_summary_df = pd.DataFrame({\n",
    "    'Class': loc_class_names,\n",
    "    f'Hit Loc Precision (Top K {top_k})': base_loc_class_precisions\n",
    "\n",
    "})\n",
    "\n",
    "display(trans_loc_summary_df)\n",
    "display(base_loc_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "launch_speed    4.415579\n",
       "hc_x            7.245790\n",
       "hc_y            7.752304\n",
       "launch_angle    9.569696\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(cont_true - trans_cont_preds).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
